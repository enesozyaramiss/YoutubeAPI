{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43bc2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Video Title: we are so excited to be performing for our EYEKONS again ðŸ’— #mallofamerica #KATSEYE\n",
      "Duration: PT6S\n",
      "Video Link: https://www.youtube.com/watch?v=rYDI0Vgh_3Q\n",
      "\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=rYDI0Vgh_3Q\n",
      "[youtube] rYDI0Vgh_3Q: Downloading webpage\n",
      "[youtube] rYDI0Vgh_3Q: Downloading ios player API JSON\n",
      "[youtube] rYDI0Vgh_3Q: Downloading player a62d836d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] rYDI0Vgh_3Q: nsig extraction failed: Some formats may be missing\n",
      "         n = 0RVwsZBilV7AMara- ; player = https://www.youtube.com/s/player/a62d836d/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] rYDI0Vgh_3Q: nsig extraction failed: Some formats may be missing\n",
      "         n = xzUHaZam5AtGt4GEb ; player = https://www.youtube.com/s/player/a62d836d/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] rYDI0Vgh_3Q: Downloading m3u8 information\n",
      "[info] Testing format 616\n",
      "[info] rYDI0Vgh_3Q: Downloading 1 format(s): 616+140\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 1\n",
      "[download] Destination: video1.f616.mp4\n",
      "[download] 100% of    2.95MiB in 00:00:01 at 2.47MiB/s                 \n",
      "[download] Destination: video1.f140.m4a\n",
      "[download] 100% of   92.59KiB in 00:00:00 at 553.21KiB/s \n",
      "[Merger] Merging formats into \"video1.mp4\"\n",
      "Deleting original file video1.f140.m4a (pass -k to keep)\n",
      "Deleting original file video1.f616.mp4 (pass -k to keep)\n",
      "Video baÅŸarÄ±yla indirildi ve video1.mp4 olarak kaydedildi!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from google.auth.transport.requests import Request\n",
    "from datetime import datetime, timedelta\n",
    "from yt_dlp import YoutubeDL  # YouTubeDL module\n",
    "import isodate  # To handle durations in ISO 8601 format\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Hide warnings\n",
    "\n",
    "# Google API credentials and YouTube Data API service configuration\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "def get_authenticated_service():\n",
    "    credentials = None\n",
    "    if os.path.exists(\"token.pickle\"):\n",
    "        with open(\"token.pickle\", \"rb\") as token:\n",
    "            credentials = pickle.load(token)\n",
    "\n",
    "    if not credentials or not credentials valid:\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            try:\n",
    "                credentials.refresh(Request())\n",
    "            except google.auth.exceptions.RefreshError:\n",
    "                print(\"Token refresh error. Starting a new authentication process.\")\n",
    "                os.remove(\"token.pickle\")  # Delete old token if there's an error\n",
    "                flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "                    \"client_secret.json\", scopes)\n",
    "                credentials = flow.run_local_server(port=0)\n",
    "        else:\n",
    "            flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "                \"client_secret.json\", scopes)\n",
    "            credentials = flow.run_local_server(port=0)\n",
    "\n",
    "        with open(\"token.pickle\", \"wb\") as token:\n",
    "            pickle.dump(credentials, token)\n",
    "\n",
    "    return googleapiclient.discovery.build(\"youtube\", \"v3\", credentials=credentials)\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    # Retrieve video details, including language and duration\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet,contentDetails\",  # contentDetails will get us the duration\n",
    "        id=\",\".join(video_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response['items']\n",
    "\n",
    "def is_video_short_enough(video):\n",
    "    # YouTube returns the duration in ISO 8601 format (e.g., PT30S)\n",
    "    duration = video['contentDetails']['duration']\n",
    "    \n",
    "    # Convert duration to seconds\n",
    "    duration_seconds = parse_duration_to_seconds(duration)\n",
    "    \n",
    "    # Filter out videos longer than 30 seconds\n",
    "    return duration_seconds <= 30\n",
    "\n",
    "def parse_duration_to_seconds(duration):\n",
    "    # Function to convert ISO 8601 duration from YouTube (e.g., PT1M30S) into seconds\n",
    "    return isodate.parse_duration(duration).total_seconds()\n",
    "\n",
    "def is_video_in_english(video):\n",
    "    # Language information is in the snippet section (defaultAudioLanguage or defaultLanguage)\n",
    "    language = video['snippet'].get('defaultAudioLanguage', video['snippet'].get('defaultLanguage', ''))\n",
    "    return language == 'en'\n",
    "\n",
    "def get_trending_entertainment_shorts_videos_in_usa(youtube, max_results=10):\n",
    "    # Calculate the date one day ago\n",
    "    one_day_ago = datetime.utcnow() - timedelta(days=1)\n",
    "    published_after = one_day_ago.isoformat(\"T\") + \"Z\"\n",
    "    \n",
    "    # Make a search request to get the short video IDs\n",
    "    request = youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        type=\"video\",\n",
    "        order=\"viewCount\",  # Get the most-watched videos\n",
    "        videoDuration=\"short\",  # Only get Shorts videos\n",
    "        publishedAfter=published_after,\n",
    "        regionCode=\"US\",  # Content from the USA\n",
    "        relevanceLanguage=\"en\",  # Content in English\n",
    "        videoCategoryId=\"10\",  # Category ID for Entertainment\n",
    "        maxResults=max_results * 2  # Get more results for filtering\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # List the video IDs\n",
    "    video_ids = [item['id']['videoId'] for item in response['items']]\n",
    "    \n",
    "    # Retrieve video details including duration and language\n",
    "    video_details = get_video_details(youtube, video_ids)\n",
    "    \n",
    "    # Filter videos by duration and language (English)\n",
    "    short_english_videos = [video for video in video_details if is_video_short_enough(video) and is_video_in_english(video)]\n",
    "\n",
    "    return short_english_videos[:max_results]\n",
    "\n",
    "def download_video(video_id, output_filename=\"video1.mp4\"):\n",
    "    # If a file with the same name exists, delete it\n",
    "    if os.path.exists(output_filename):\n",
    "        os.remove(output_filename)\n",
    "        print(f\"Previous {output_filename} file deleted.\")\n",
    "\n",
    "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo+bestaudio/best',  # Select the best video and audio quality\n",
    "        'outtmpl': output_filename,  # Set the output file name and extension\n",
    "    }\n",
    "    \n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "    print(f\"Video downloaded and saved as {output_filename}!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    youtube = get_authenticated_service()\n",
    "    \n",
    "    # Get the most-watched English short videos from the USA\n",
    "    trending_videos = get_trending_entertainment_shorts_videos_in_usa(youtube, max_results=10)\n",
    "\n",
    "    # Print video details and download the videos\n",
    "    for idx, video in enumerate(trending_videos):\n",
    "        video_id = video['id']\n",
    "        title = video['snippet']['title']\n",
    "        duration = video['contentDetails']['duration']\n",
    "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "        print(f\"{idx + 1}. Video Title: {title}\")\n",
    "        print(f\"Duration: {duration}\")\n",
    "        print(f\"Video Link: {video_url}\\n\")\n",
    "        \n",
    "        # Download the video\n",
    "        download_video(video_id, output_filename=\"video1.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f268d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12df00fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Title: Human vs Jet Engine\n",
      "Hashtags: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_video_hashtags(description):\n",
    "    # Using a simple regex to identify hashtags\n",
    "    hashtags = re.findall(r\"#\\w+\", description)\n",
    "    return hashtags\n",
    "\n",
    "def get_video_details_with_hashtags(youtube, video_ids):\n",
    "    # Retrieve video details including description and other information\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet\",\n",
    "        id=\",\".join(video_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response['items']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    youtube = get_authenticated_service()\n",
    "    \n",
    "    # Example: using a video ID here\n",
    "    video_ids = [\"ZNt_GoOBHq8\"]  # Enter a video ID here\n",
    "    video_details = get_video_details_with_hashtags(youtube, video_ids)\n",
    "    \n",
    "    for video in video_details:\n",
    "        title = video['snippet']['title']\n",
    "        description = video['snippet']['description']\n",
    "        hashtags = get_video_hashtags(description)\n",
    "        \n",
    "        print(f\"Video Title: {title}\")\n",
    "        print(f\"Hashtags: {hashtags}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8071c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064973e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
